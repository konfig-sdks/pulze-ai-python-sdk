# coding: utf-8

"""
    Pulze.ai API

    At Pulze it's our mission to supercharge today's workforce with AI to maximize the world's prosperity. We are doing so by enabling companies of any size to securely leverage Large Language Models (LLM) and easily build AI features into their apps. Our enterprise platform has access to all best in class LLMs and can route user requests to the most relevant model to get the highest quality response at the best price thanks to our smart meta model. End users can leverage pre-built applications, such as our Marketing AI product, or build custom apps on top of the Pulze Platform.  We are a VC Funded, early stage startup based in San Francisco.

    The version of the OpenAPI document: 0.1.0
    Generated by: https://konfigthis.com
"""

from datetime import datetime, date
import typing
from enum import Enum
from typing_extensions import TypedDict, Literal, TYPE_CHECKING
from pydantic import BaseModel, Field, RootModel

from pulze_ai_python_sdk.pydantic.pulze_completion_request import PulzeCompletionRequest
from pulze_ai_python_sdk.pydantic.pulze_engine_response import PulzeEngineResponse
from pulze_ai_python_sdk.pydantic.request_in_db_base_children import RequestInDBBaseChildren

class RequestInDBBase(BaseModel):
    # ID of the request
    id: str = Field(alias='id')

    # The response object
    response: PulzeEngineResponse = Field(alias='response')

    # The ID of the app that performed the request
    app_id: typing.Optional[str] = Field(None, alias='app_id')

    children: typing.Optional[RequestInDBBaseChildren] = Field(None, alias='children')

    # When a request requires multiple intermediate calls, they are stored as 'no costs incurred' -- that way we can store the costs, but don't charge the user
    costs_incurred: typing.Optional[bool] = Field(None, alias='costs_incurred')

    # A free text providing more detailed feedback
    feedback: typing.Optional[str] = Field(None, alias='feedback')

    # The rating for the request
    good_answer: typing.Optional[bool] = Field(None, alias='good_answer')

    # The name of the provider's model which was used to answer the request
    namespace: typing.Optional[str] = Field(None, alias='namespace')

    # The parent of the Request, if any. Requests which are part of a series of sub-requests (like multiple LLM calls, or RAG) will have the final, resulting Log as parent.
    parent: typing.Optional[typing.Union[bool, date, datetime, dict, float, int, list, str, None]] = Field(None, alias='parent')

    # Reference to the ID of the parent of this log. A log has a parent when it's a subrequest used to retrieve the final answer.
    parent_id: typing.Optional[str] = Field(None, alias='parent_id')

    # The payload sent with the request
    payload: typing.Optional[PulzeCompletionRequest] = Field(None, alias='payload')

    # How much is logged? 1: everything, 2: mask request+response (but show log), 3: Not visible, not retrievable, no information stored.
    privacy_level: typing.Optional[Literal[1, 2, 3]] = Field(None, alias='privacy_level')

    # The prompt in text format
    prompt: typing.Optional[str] = Field(None, alias='prompt')

    # The type of request (text completion or chat) the user sends and expects back
    request_type: typing.Optional[Literal["completions", "chat_completions"]] = Field(None, alias='request_type')

    # The response in text format
    response_text: typing.Optional[str] = Field(None, alias='response_text')

    # The status code of the request to the AI model
    status_code: typing.Optional[int] = Field(None, alias='status_code')
    class Config:
        arbitrary_types_allowed = True
